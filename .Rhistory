summary <- entrez_summary(db="pubmed", id=res$ids)
pt <- summary$pubtype
any(grepl("Guideline|Consensus|Recommendation|Practice Guideline|Position Statement",
pt, ignore.case = TRUE))
}
# ---- STEP 4: Loop through your publications ----
results <- list()
for (my_doi in pubs) {
message("Checking: ", my_doi)
citing_df <- get_citing_dois(my_doi)
if (!is.null(citing_df) && nrow(citing_df) > 0) {
citing_df <- citing_df %>%
mutate(is_guideline = map_lgl(doi, is_guideline),
cited_my_doi = my_doi) %>%
filter(is_guideline)
if (nrow(citing_df) > 0) {
results[[length(results)+1]] <- citing_df
}
}
}
guideline_citations <- bind_rows(results)
View(guideline_citations)
#### DIMENSIONS ####
ds_authenticate()
??ds_authenticate
getAnywhere(ds_authenticate)
altmetric(doi = '10.1016/S1473-3099(25)00382-2')
altmetric(doi = '10.1016/j.ijid.2025.108023') ->a
dimensions <- map(dois, function(d) {
res <- tryCatch(altmetric(d), error = function(e) NULL)
# Skip nulls or non-results
if (is.null(res)) return(NULL)
# Coerce to tibble safely (convert list → data.frame)
res_df <- as.data.frame(res, stringsAsFactors = FALSE)
if (nrow(res_df) > 0) {
return(res_df)
} else {
return(NULL)
}
})
dimensions <- bind_rows(dimensions)
dois
altmetric(doi = "10.1016/j.joi.2017.08.007")
install.packages("dimensionsR")
library(dimensionsR)
altmetric(doi = '10.1016/S1473-3099(25)00382-2') %>%
pivot_longer(cols = everything(),
names_to = "test", values_to = "test2",
values_ptypes = list(test2=as.character(), test=as.character()))
library(tidyverse)
library(tidylog)
altmetric(doi = '10.1016/S1473-3099(25)00382-2') %>%
pivot_longer(cols = everything(),
names_to = "test", values_to = "test2",
values_ptypes = list(test2=as.character(), test=as.character()))
#### DIMENSIONS ####
ds_authenticate()
dimensions <- map(dois, function(d) {
res <- tryCatch(altmetric(d), error = function(e) NULL)
# Skip nulls or non-results
if (is.null(res)) return(NULL)
# Coerce to tibble safely (convert list → data.frame)
res_df <- as.data.frame(res, stringsAsFactors = FALSE)
if (nrow(res_df) > 0) {
return(res_df)
} else {
return(NULL)
}
})
dimensions <- bind_rows(dimensions)
View(dimensions)
dimensions <- map(dois, function(d) {
res <- tryCatch(altmetric(d), error = function(e) NULL)
# Skip nulls or non-results
if (is.null(res)) return(NULL)
# Coerce to tibble safely (convert list → data.frame)
res_df <- as.data.frame(res, stringsAsFactors = FALSE)
if (nrow(res_df) > 0) {
return(res_df)
} else {
return(NULL)
}
})
View(dimensions)
altmetric(doi = '10.1016/S1473-3099(25)00382-2')
altmetric(doi = '10.1016/S1473-3099(25)00382-2')
doi = "10.1016/j.joi.2017.08.007"
df <- altmetric(doi = doi)
remotes::install_github("netique/scihubr")
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = FALSE,
path = '~/Downloads/')
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = FALSE,
path = '~/Downloads')
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = FALSE,
path = '~/Downloads/pdf1.pdf')
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = FALSE,
path = "~/Downloads/pdf1.pdf")
"~/Downloads/pdf1.pdf"
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = FALSE)
scihubr::download_paper("10.1007/s00134-022-06825-8",
open = TRUE)
scihubr::download_paper(query = "10.1007/s00134-022-06825-8",
open = TRUE)
scihubr::download_paper(query = "10.1007/s00134-022-06825-8")
library(scihubr)
remove.packages("scihubr")
sci_down??
??sci_down
devtools::install_github("KiayangQ/paperdigger")
library(paperdigger)
## basic example code
paper_dig()
paper_dig()
sci_down('~/Downloads/Exported Items.csv', original = 'Dois')
a <- read.csv('~/Downloads/Exported Items.csv')
sci_down(a$DOI)
sci_down(a$DOI,original = 'Dois')
paper_dig()
sci_down('~/Downloads/Exported Items.csv', original = 'Dois')
sci_down('~/Downloads/Exported Items.csv', original = 'Dois', ext_files = 'csv')
sci_down('~/Downloads/Exported Items.csv', original = 'Dois')
ext_files = 'csv'
sci_down('~/Downloads/Exported Items.csv', original = 'Dois')
sci_down('~/Downloads/Exported Items.csv', original = 'Dois')
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
url <- "http://sci-hub.se"
dois <- a %>% select(DOI) %>% pull()
library(tidyverse)
dois <- a %>% select(DOI) %>% pull()
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
added <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
sci_down <- function(path,input_url=NULL,original="Database"){
# read file
data_bib <- read_bib(path,original)
dois <- data_bib$dois
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
added <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
sci_down <- function(path,input_url=NULL,original="Dois"){
# read file
dois <- dois
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
added <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
url <- "http://sci-hub.se"
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pb
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
original = 'Dois'
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
sci_down <- function(path,input_url=NULL,original="Dois"){
# read file
dois <- dois
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
sci_down(original = 'Dois')
dois <- a %>% select(DOI) %>% filter(!is.na(DOI)) %>% pull()
sci_down <- function(path,input_url=NULL,original="Dois"){
# read file
dois <- read
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
sci_down <- function(path,input_url=NULL,original="Dois"){
# read file
dois <- dois
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
sci_down(original = 'Dois')
# read file
dois <- dois
sci_down(original = 'Dois')
dois
dois <- a %>% select(DOI) %>% filter(DOI!="") %>% pull()
# read file
dois <- dois
sci_down <- function(path,input_url=NULL,original="Dois"){
# read file
dois <- dois
# check url
if (is.null(input_url)){
url <- "http://sci-hub.se"
}else{
url <- input_url
}
# progress check
pb <- progress::progress_bar$new(total = length(dois),clear = FALSE)
pbadded <- round(runif(1,min=10000,max=99999))
dir_name <- paste0("paper",added)
dir.create(file.path(dir_name))
loc_get <- purrr::map2(dois,dir_name,purrr::safely(function(x,y) {
pb$tick()
data1 <- sci_down_orginal(url=url,dois=x,dir=y)
Sys.sleep(2)
return(data1)
},
otherwise = message("Some links may not work, please check them and download manually"))) %>%
purrr::transpose()
# collecting
success <- purrr::map_dbl(loc_get$error,function(x){
note <- c()
if (is.null(x)){
failure=1
}else{
failure=0
}
rbind(note,failure)
})
# wrangling
data <- purrr::map(loc_get,~ purrr::discard(.x, is.null))$result %>% unlist() %>% as.data.frame(.,stringsAsFactors = FALSE)
locs <-  data$. %>% stringr::str_split(., "#") %>% purrr::map_chr(.,function(x)`[[`(x,1) %>% `[`(.,1))
if(original=="Database") {
index <- data.frame(title=data_bib$title,dois=data_bib$dois,success)
}else if(original=="Dois"){
index <- data.frame(dois=dois,success)
}
output <- list(locs=locs,index=index)
return(output)
}
sci_down(original = 'Dois')
